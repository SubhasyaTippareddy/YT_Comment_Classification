{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwZoAUR5m7oc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('testresults.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "N0nd_2Ccm9tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(text):\n",
        "  text = text.strip('[]')\n",
        "  text = text.split()\n",
        "\n",
        "\n",
        "  int_list = [int(elem) for elem in text]\n",
        "  return int_list\n",
        "\n",
        "\n",
        "df['predictions'] = df['predictions'].apply(lambda x: process(x))"
      ],
      "metadata": {
        "id": "kNtubAWinQ5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "expanded_df = pd.DataFrame(df['labels'].to_list(), columns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], index=df.index)\n",
        "\n",
        "# Concatenate the new DataFrame with the original DataFrame\n",
        "result_df = pd.concat([df, expanded_df], axis=1)\n",
        "\n",
        "df=result_df\n"
      ],
      "metadata": {
        "id": "3lHaEWWEndxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "hB7yKP5-nrVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = 'predictions', inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "wR3e4ExtntAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_toxic = df.query('toxic==0 & severe_toxic==0 & obscene==0 & threat==0 & insult==0 & identity_hate==0')\n",
        "inappropriate = df.query('toxic!=0 & severe_toxic!=0 & obscene!=0 & threat!=0 & insult!=0 & identity_hate!=0')"
      ],
      "metadata": {
        "id": "q8pyqKtln1DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking label distribution\n",
        "fig, ax = plt.subplots(figsize=(7,7))\n",
        "class_counts = [df.toxic.value_counts()[1], df.severe_toxic.value_counts()[1] , df.obscene.value_counts()[1], df.threat.value_counts()[1], df.insult.value_counts()[1],df.identity_hate.value_counts()[1] ]\n",
        "ax.bar(df.columns[2:], class_counts, color = ['r','g','b','k','y','m','c'], width = 0.4)"
      ],
      "metadata": {
        "id": "7UzzCbazoU0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# non toxic comments out of total dataset\n",
        "labels = ['Non-Toxic\\nComments', 'Toxic / Inappropriate\\nComments']\n",
        "fig = plt.figure(figsize = (7, 7))\n",
        "explode = [0.0, 0.2]\n",
        "plt.pie([non_toxic.shape[0], df.shape[0] - non_toxic.shape[0]], autopct='%1.0f%%', labels=labels, explode=explode)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pEwKLPApoacx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}